\graphicspath{{body/fig/}}

\chapter{Body}
\label{chap:body}

\section{Model Definition}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{model-drawing.png}
    \caption[I am the short caption that appears in the list of figures, without references.]{ I am a caption below the figure of course}
    \label{fig:model-drawing}
\end{figure}

This is a reference to Figure~\ref{fig:model-drawing}

RVs:
\begin{itemize}
    \item Hidden Drought State RVs $\equiv S_t = \{1,2,\dots,m\}$    
    \item Attribute RVs $\equiv A^{(n)}_t = \{1,2,\dots,C_n\}$
\end{itemize}

Some further notation:
\begin{itemize}
    \item $\vec{S}_{1:T}  = \{S_1,S_2,\dots,S_T\}$    
    \item $A_{1:T} = \{\vec{A}_1,\vec{A}_2,\dots,\vec{A}_T\}$
    \begin{itemize}
        \item Where $\vec{A}_t = \{ A^{(1)}_t, A^{(2)}_t, \dots, A^{(N)}_t\}$
    \end{itemize}
\end{itemize}


\subsection{Joint Distribution}

\[
\begin{align}
    &p(S_1, S_2, \dots, S_T, A^{(1)}_1, A^{(2)}_1, \dots, A^{(N)}_1, A^{(1)}_2, \dots, A^{(N)}_T) \\ 
    &= p(S_1, S_2, \dots, S_T, \vec{A}_1, \vec{A}_2, \dots, \vec{A}_T) \\
    &= p(\vec{S}_{1:T}, A_{1:T}) \\
    &= p(S_1) \cdot \prod\limits_{t=1}^{T-1} p(S_{t+1} \mid S_t) \cdot \prod\limits_{n=1}^{N} \prod\limits_{t=1}^T p(A^{(n)}_t \mid S_t)
\end{align}
\]

\section{Factors}

Priors
\[
\begin{array}{c | c}
S_1 & p(S_1) \\ 
\hline
1 & \pi_1 \\ 
2 & \pi_2 \\ 
\vdots & \vdots \\
m & \pi_m \\ 
\end{array} 
\]

Transition
\[
\begin{array}{ccc}
\begin{array}{c c | c}
S_t & S_{t+1} & p(S_{t+1} \mid S_t) \\ 
\hline
1 & 1  & a_{1,1} \\ 
1 & 2  & a_{1,2} \\ 
\vdots & \vdots  & \vdots \\
1 & m  & a_{1,m} \\ 
2 & 1  & a_{2,1} \\ 
2 & 2  & a_{2,2} \\ 
\vdots & \vdots  & \vdots \\
m & m  & a_{m,m} \\ 
\end{array} 
&
\equiv
&
P^1 = 
\begin{bmatrix}
a_{1,1} & a_{1,2} & \dots & a_{1,m} \\
a_{2,1} & a_{2,2} & \dots & a_{2,m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m,1} & a_{m,2} & \dots & a_{m,m} \\
\end{bmatrix}
\end{array} 
\]


Emission
\[
\begin{array}{c c | c}
A^{(n)}_t & S_t & p(A^{(n)}_t \mid S_t) \\ 
\hline
1 & 1  & b_1^{(n)}(1) \\ 
1 & 2  & b_2^{(n)}(1) \\ 
\vdots & \vdots  & \vdots \\
1 & m  & b_m^{(n)}(1) \\ 
2 & 1  & b_1^{(n)}(2) \\ 
2 & 2  & b_2^{(n)}(2) \\ 
\vdots & \vdots  & \vdots \\
C_n & m  & b_m^{(n)}(C_n) \\ 
\end{array} 
\]


\section{EM Theory}

\begin{itemize}
    \item $\mathcal{H} = (S_t)_{t=1}^T$
    \item $\mathcal{D} = (\vec{A}_t)_{t=1}^T$ 
    \item $\Theta = (\vec{\theta}_1, \vec{\theta}_2, \vec{\theta}_3)$
    \item $\vec{\theta}_1 = \{\pi_1, \pi_2, \dots, \pi_m\} \equiv S_1 \text{ Priors}$
    \item $\vec{\theta}_2 = \{a_{1,1}, a_{1,2}, \dots, a_{m,m}\} = P^1 \equiv \text{Transition Probabilities}$
    \item $\vec{\theta}_3 = \{b_1^{(n)}(1), b_2^{(n)}(1), \dots, b_1^{(N)}(m)\} = P^1 \equiv \text{Emission Probabilities}$
\end{itemize}

\subsection{E-Step}

Hold $\Theta$ fixed and choose $q$ such that 
\[
    \begin{aligned}
        q(\mathcal{H}) &= p(\mathcal{H} \mid \mathcal{D}, \Theta) \\
        &= p(\vec{S}_{1:T} \mid A_{1:T}, \Theta)
    \end{aligned}
\]


\subsection{M-Step}

Hold $q$ fixed and optimise $\mathscr{L}(q, \Theta)$ w.r.t $\Theta$ 


After some math, this means finding $\Theta$ such that:
\[
    \begin{aligned}
        \Theta &= \underset{\Theta}{\operatorname{argmax}} Q(\Theta) \\
        &= \underset{\Theta}{\operatorname{argmax}} \sum\limits_{\mathcal{H}} q(\mathcal{H}) \cdot \text{log} \hspace{0.1cm} p(\mathcal{D}, \mathcal{H} \mid \Theta)
    \end{aligned}
\]




\newpage

\section{Update Equations}
Priors:
\begin{equation}
\pi_i^{\text{new}} = q(S_1=i)
\label{eq:prior_update}
\end{equation}

Transition Probabilities:
\begin{equation}
a_{ij}^{\text{new}} = \frac{\sum\limits_{t=1}^{T - 1} q(S_t=i,S_{t+1}=j)}{\sum\limits_{t=1}^{T-1} q(S_t=i)}
\label{eq:transition_update}
\end{equation}


Emission Probabilities:
\begin{equation}
b_i^{(n)}(j)^{\text{new}} = \frac{\sum\limits_{t=1}^T q(S_t = i) \cdot I(A_t^{(n)} = j)}{\sum\limits_{t=1}^T q(S_t = i)}
\label{eq:emission_update}
\end{equation}

We can now reference these equations by their label: Equation~\ref{eq:prior_update}, Equation~\ref{eq:transition_update} or Equation~\ref{eq:emission_update}. This is wicked, lemme tell you

\newpage

\section{FIGURES TIME}

things before figure



\section{Determining $m$}


We are using AIC, BIC and maximum log likelihood to do this. Here are the formulas:
\[
    \begin{aligned}
        AIC &= -2 \cdot \text{log} \; L(\Theta) + 2p \\
        BIC &= -2 \cdot \text{log} \; L(\Theta) + p \cdot \text{log} \; k
    \end{aligned}
\]
Where:
\begin{itemize}
    \item $L(\Theta) \equiv$ the maximized value of the likelihood function for the estimated model
    \item $p \equiv$ the number of free parameters, 
    \item $k \equiv$ the number of data points. 
\end{itemize}


The idea is that we are going to sweep $m$, this means creating many models with different values of $m$, and choose the model that minimizes both AIC \& BIC, whilst maximising $L(\Theta)$. Here is a more comprehensive criteria for choosing a particular $m$:

\begin{enumerate}
    \item Primary: lowest BIC (preferred if you want parsimony, BIC penalizes complexity strongly).
    \item Secondary: lowest AIC.
    \item Also look at the log-likelihood curve: if $\text{log} \; L(\Theta)$ improves only marginally as $m$ increases, choose the simpler model (elbow rule).
\end{enumerate}

But okay, lets see what the particular values are for our BIC \& AIC calculations


\subsection{What is $k$}
We will first look at $k \equiv$ the number of data points: Not sure, can either see each observation as a vector, therefore we have $T$, or we can see each $a_t^{(n)}$ as an observation, and in that case we would have $T \times N$ observations.

\subsection{What is $p$}
- Next we look at $p \equiv$ the number of free parameters. Look more into this. See Occons Razor (A principled method to model selection and how BIC is an approximation of this), in the, use $m-1$, so we will have:


\[
    \begin{aligned}
        p &= (m-1) + m(m-1) + \sum\limits_{n=1}^N m(C_n - 1) \\ 
        &= m^2 - 1 +m\sum\limits_{n=1}^N (C_n - 1)
    \end{aligned}
\]


\subsection{How To Get $\ell(\Theta)$}

This is the real kicker...
\vspace{1cm}

Of course the likelihood is the probability our data is observed, this means finding:
\[
    \begin{aligned}
        \ell(\Theta) &= p(A_1^{(1)} = a_1^{(1)}, A_1^{(2)} = a_1^{(2)}, \dots, A_T^{(N)} = a_T^{(N)} \mid \Theta) \\ 
        &= p(A_{1:T}^\text{obs} \mid \Theta)
    \end{aligned}
\]

Note: $\text{Observed Data} = (a_1^{(1)}, a_1^{(2)}, \dots, a_T^{(N)})$

To do this, we will use the Forward Algorithm (also note that have this (obs) superset makes things very verbose and will be omitted from here on out):

We begin by defining the factor $p(\vec{A}_t \mid S_t = i)$
\begin{itemize}
    \item Recall, $\vec{A}_t = \{A_t^{(1)}, A_t^{(2)}, \dots A_t^{(N)} \}$
    \item Because of our model and the independent properties and things, we know that:
        \[
            \begin{aligned}
                p(\vec{A}_t \mid S_t = i) &= p(A_t^{(1)}, A_t^{(2)}, \dots, A_t^{(N)} \mid S_t = i) \\
                &= p(A_t^{(1)} \mid S_t = i) \cdot p(A_t^{(2)} \mid S_t = i) \dots p(A_t^{(N)} \mid S_t = i) \\ 
                &= \prod\limits_{n=1}^N p(A_t^{(n)} \mid S_t = i) \\
                &= \prod\limits_{n=1}^N e_i^{(n)}(a_t^{(n)})
            \end{aligned}
        \]
\end{itemize}

Lets now look at the Forward Algorithm

\begin{itemize}
    \item We first define
\[
    \begin{aligned}
        \alpha_t(i) &= p(S_t = i, A_{1:t}^{\text{obs}} \mid \Theta) \\
        &= p(S_t = i, \vec{A}_1, \vec{A}_2, \dots, \vec{A}_t \mid \Theta)
    \end{aligned}
\]
    \item We begin at $t=1$:
\[
    \begin{aligned}
        \alpha_1(i) &= p(S_1 = i, A_{1:1}^{\text{obs}} \mid \Theta) \\
        &= p(S_1 = i, \vec{A}_1 \mid \Theta) \\
        &= p(S_1) \cdot p(\vec{A}_1 \mid S_1 = i, \Theta) \\
    \end{aligned}
\]

    \item Then to move to the next time step: 
\[
    \alpha_{t+1}(j) &= (\sum\limits_{i=1}^m \alpha_t(i) \cdot p_{i,j}) \cdot p(\vec{A}_{t+1} \mid S_{t+1} = j, \Theta)
\]
    \item Thus, by the end we will have $\alpha_T(i) = p(A_{1:T}, S_T = i \mid \Theta)$
    \item Then finally we can obtain our likelihood by marginalising out $S_T$
        \[
            \begin{aligned}
                \sum\limits_{i=1}^m \alpha_T(i) &= \sum\limits_{S_t} p(A_{1:t}, S_t \mid \Theta) \\ 
                &= p(A_{1:t} \mid \Theta) \\ 
                &= \ell(\Theta)
            \end{aligned}
        \]
\end{itemize}

Okay, lets regroup. Just so we fully get it. This is done after our model has been fitted and we already have our final $\Theta$. There is also no factors going on here. Our parameters ($\Theta$) are the probabilities in themselves. So when we observed our data $p(A_t^{(n)} = a_t^{(n)} | S_t = i)$ we are in essence choosing the value $b^{(n)}_i(a_t^{(n)})$ (Note, these $b$'s will have to change to $e$ or something...). And thus we have actual values we are playing with, thus pure math, not factors.



\section{Meditating a little bit more on model output}

\section{What I have been doing}

We are computing the pointwise marginal MAP, often called the Maximum Posterior Marginal (MPM) rule. For each time 
$t$, we pick: 
\[
    \hat{s}_t = \underset{s}{\operatorname{argmax}} \;\; p(S_t = s \mid A_{1:T}, \Theta)
\]

The MPM picks the most likely state at each time independently — which can lead to an impossible or very unlikely global sequence (eg. $S_t \equiv$ Very Wet, then $S_{t+1} \equiv$ Very Dry). It maximizes expected per-time classification accuracy, but it does not maximize the joint posterior probability of the entire sequence.

\section{Viterbi Algorithm}

The paper recommends the Viterbi algorithm, which finds
\[
    \vec{s}^* = \underset{\vec{S}_{1:T}}{\operatorname{argmax}} \;\; p(\vec{S}_{1:T}\mid A_{1:T}, \Theta)

\]

ie. The single state sequence with the highest joint posterior probability. That sequence respects transitions and is temporally coherent.




Okay, Just a little reminder, we have used the LBU paired with EM. I spoke to my professor and he mentioned that because of the model structure, we are actually constructing a Junction Tree meaning we get exact inference. Additionally, because of how the junction tree we start from the leaf nodes, the formulation of using the JTREE vs Forward-Backward is actually the exact same (Check math behind this...). 

Anyway, we have our model output now $p(\vec{S}_{1:T} \mid A_{1:T}, \Theta)$ which is an exact measure. How do i know get the output of my model. The paper I am implementing says this: "With the estimated optimal DNBC parameters, the most probable path of the latent drought state that maximizes P(A|·) together with the probability of each state at every time step can be obtained using the Viterbi algorithm (Rabiner 1989)." Right now I am simply taking the maximum confidence for each $p(S_t \mid A_{1:T}, \Theta)$. This is most probably wrong. What must I do, explain to me what i must do and why what im doing is wrong (if it is wrong.)








\newpage
\section{THIS NEEDS TO BE CLEANED UP, NOT SURE WHAT THESE THINGS BELOW ARE}


Reminder: These are factors we have available:
\begin{itemize}
\item $q(\mathcal{H}) = p(\vec{S}_{1:T} \mid A_{1:T}^{\text{obs}}, \Theta)$
\item $p(S_1)$
\item $p(S_{t+1} \mid S_t)$
\item $p(A^{(n)}_t \mid S_t)$
\end{itemize}

We want $\text{log} \; \ell(\Theta) = \text{log} \; p(A_{1:T}^{\text{obs}} \mid \Theta)$

Math to get there:
\begin{enumerate}
    \item Start With Each $p(A_t^{(n)} \mid S_t)$
    \item For Each $A_t^{(n)}$
        \begin{enumerate}
            \item Observe data point $a_t^{(n)}$ to get: $p(A_t^{(n)} = a^{(n)}_t \mid S_t)$
            \item Get $p(A_t^{(n)} = a^{(n)}_t)$ understanding that: 
                \[
p(A_t^{(n)} = a^{(n)}_t) = \sum\limits_{S_t} p(A_t^{(n)} = a^{(n)}_t \mid S_t) \cdot p(S_t)
                \]
                This $p(S_t)$ is our $q(\mathcal{H})$
        \end{enumerate}
    \item Then of course, we multiply these to get 
        \[
p(A_{1:T}^\text{obs}) = \prod\limits_{n=1}^N\prod\limits_{t=1}^T p(A_t^{(n)} = a^{(n)}_t)
        \]
    \item These will likely underflow so we insert log now: 
        \[
            \text{log} \; \ell(\Theta) = \text{log} \; p(A_{1:T}^\text{obs}) = \sum\limits_{n=1}^N\sum\limits_{t=1}^T \text{log} \; p(A_t^{(n)} = a^{(n)}_t)
        \]
\end{enumerate}

Thoughts?






If I can still use the forward equations, let me know. Otherwise I need to calculate the full joint distr and marginalise out?


A little bit embarrassing but how exactly do we get the log likelihood, the naive way. My understanding is that we:
\begin{enumerate}
    \item Calculate the full joint distribution: 
    \[
p(\vec{S}_{1:T}, A_{1:T}) = p(S_1) \cdot \prod\limits_{t=1}^{T-1} p(S_{t+1} \mid S_t) \cdot \prod\limits_{n=1}^{N} \prod\limits_{t=1}^T p(A^{(n)}_t \mid S_t)
    \]
    \item Marginalise out all $S_t$: 
        \[
p(A_{1:T} \mid \Theta) = \sum_{S_{1:T}} p(\vec{S}_{1:T}, A_{1:T} \mid \Theta)
        \]
    \item Then Observe Actual Data and sum the probs?
        \[
            \text{Likelihood} = \sum p(A_{1:T} = \mathcal{D}) ??
        \]
\end{enumerate}


I don't know what you mean by me being stuck. I get parameters which are the probabilities to the factors I am looking for. The model output is the max value $S_t$ which i get from my $q$ function. Let me know if I am overlooking something.


With regards to the AIC \& BIC calcs. you have here $\ell(\Theta) = \sum_{S_{1:T}} p(\vec{S}_{1:T}, A_{1:T})$ but this leaves us with a factor not a single value? This is required for AIC and BIC which are single values? This is why I thought you must sum over observations?




Okay Ill stop faffing. Forward-Backward is new, I didnt want to waste a time sink learning it. Especially because this LBU + EM is much more flexible of a route which is good for me since I plan to expand this model. One idea I have is to introduce second-order markov property to the thing. Is Forward-Backward still feasible for a DNBC with the second order markov property? If not I am sticking to LBU. And thus maybe need an alternative to AIC and BIC. But let me know your thoughts.


\newpage

\section{Questions}

\begin{enumerate}
    \item Forward-Backward Equations. I have to right? From what I can see it applies to second order as well when we vectorise our states? 
        \begin{itemize}
            \item Its only really a problem to try and get $log \; \ell(\Theta)$ for AIC and BIC. Besides this it works fine? 
            \item is extracting $S_t$ from $q(\mathcal{H})$ fine and correct? Since we want $p(S_t)$ not \\ 
                $p(S_t \mid A_{1:T})$...
        \end{itemize}
    \item Based on this as about LBU things:
        \begin{enumerate}
            \item emdw has this \verb|#include "lbu2_cg.hpp"|. What is this??
            \item Ask about LTRIP vs other methods $\rightarrow$ Other Methods: BETHE, JTREE
        \end{enumerate}
    \item Breaking symmetry for the priors $p(S_1)$. Is it necessary?
    \item With regards to BIC \& AIC, we need $k \equiv \text{Number of Free Parameters}$ (See calcs on \verb|model-dev-clean| pg 11)
    \item Discrete vs Cts Attribute RVs. See \verb|model-dev-clean| pg 10
    \item \verb|main.cpp| line 951

\end{enumerate}


\section{Forward-Backward}



\begin{itemize}
    \item Initial: $\pi_i = P(S_1=i)$.
    \item Transition: $a_{ij} = P(S_{t+1}=j \mid S_t=i)$.
    \item Emission Probabilities: $b_i^{(n)}(j) = p(A_t^{(n)}=j \mid S_t=i)$.
\end{itemize}


\subsection{Define Forward Values}

\[
    \alpha_t(i) = p(S_t = i, A_{1:t}^{\text{obs}} \mid \Theta)
\]

\subsection{Define Backward Values}

\[
    \beta_t(i) = p( A_{t+1:T}^{\text{obs}} \mid S_t = i, \Theta)
\]


\subsection{Updates}

First Define:
\[
    \gamma _t(i) = p(S_t = i \mid A_{1:T}^{\text{obs}}, \Theta) = \frac {p(S_t=i, A_{1:T}^{\text{obs}} \mid \Theta )}{p(A_{1:T}^{\text{obs}} \mid \theta )} = \frac{\alpha_t(i) \beta_t(i)}{\sum\limits_{k=1}^m\alpha_t(k) \beta_t(k)}
\]

Node marginals:

\[
  \gamma_t(i) = P(S_t=i\mid A_{1:T},\Theta) = \frac{\alpha_t(i)\beta_t(i)}{\sum_{k=1}^m \alpha_t(k)\beta_t(k)}.
\]

Pairwise marginals:

\[
    \xi_t(i,j) = P(S_t=i, S_{t+1}=j \mid A_{1:T},\Theta) = \frac{\alpha_t(i) a_{ij} P(A_{t+1}\mid S_{t+1}=j) \beta_{t+1}(j)}{\sum\limits_{p=1}^m \sum\limits_{q=1}^m \alpha_t(p) a_{pq} P(A_{t+1}\mid S_{t+1}=q)\beta_{t+1}(q)}.

\]

\newpage

1. Forward $\alpha_t(i)=P(A_{1:t},S_t=i \mid \theta)$ and backward $\beta_t(i)=P(A_{t+1:T}\mid S_t=i,\theta)$. Use scaling or log-space.
2. Responsibilities:

   $$
   \gamma_t(i) \equiv P(S_t=i\mid A_{1:T},\theta)=\frac{\alpha_t(i)\,\beta_t(i)}{\sum_{\ell}\alpha_t(\ell)\beta_t(\ell)}.
   $$
3. Pairwise responsibilities:

   $$
   \xi_t(i,j) \equiv P(S_t=i,S_{t+1}=j\mid A_{1:T},\theta)=
   \frac{\alpha_t(i)\,a_{ij}\,P(A_{t+1}\mid S_{t+1}=j)\,\beta_{t+1}(j)}{\sum_{p,q}\alpha_t(p)\,a_{pq}\,P(A_{t+1}\mid S_{t+1}=q)\,\beta_{t+1}(q)}.
   $$

For multiple independent sequences $n=1,\dots,N$, compute $\gamma_t^{(n)}$ and $\xi_t^{(n)}$ per sequence and sum where needed.

# “Baum’s auxiliary function” = EM $Q$-function

$$
Q(\theta\mid\theta^{\text{old}}) \;=\; \mathbb{E}_{S_{1:T}\mid A_{1:T},\theta^{\text{old}}}\!\left[\log P(S_{1:T},A_{1:T}\mid \theta)\right].
$$

Expanding the complete-data log-likelihood under the DNBC factorization gives three decoupled blocks (initial, transition, emission). Maximizing $Q$ with simplex constraints $\sum_i \pi_i=1$, $\sum_j a_{ij}=1$, $\sum_k b_{i,m}(k)=1$ via Lagrange multipliers yields normalized expected counts. That’s “Baum–Welch”. Same thing you should get if you derive EM straight.

# M-step (discrete case, no priors)

Single sequence (replace sums with $\sum_n$ for multiple sequences):

**Initial:**

$$
\pi_i^{\text{new}} = \gamma_1(i).
$$

**Transition:**

$$
a_{ij}^{\text{new}} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}.
$$

**Emission for each attribute $m$ and value $k$:**

\[
b_{i,m}^{\text{new}}(k) \;=\; \frac{\sum_{t=1}^{T} \gamma_t(i)\,\mathbf{1}\{A_t^{(m)}=k\}}{\sum_{t=1}^{T} \gamma_t(i)}.
\]

