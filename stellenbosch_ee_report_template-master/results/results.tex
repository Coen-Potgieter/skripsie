\graphicspath{{results/fig/}}

\chapter{Results}
\label{chap:results}

This chapter presents the results obtained from the dynamic naive Bayes classifier (DNBC). The analysis begins with the outputs from model selection then moves to qualitative and quantitative assessment of the model’s classification performance against the input drought indices used as a benchmark.

\section{Model Selection and State Definition}

The results of the model selection procedures from Section~\ref{sec:model_selection_implementation} are presented in Figure~\ref{fig:model-selection-combined}. The plot on the left was used to determine the number of latent drought states, $m$. Both Akaike information criterion (AIC) and Bayesian information criterion (BIC) reach a minimum at $m=6$, indicated by the vertical red line. This point also corresponds to a pronounced improvement in the log-likelihood. This alignment of all three selection criteria---following the rules established in Section~\ref{sec:model_selection}---confirms that $m=6$ is the optimal number of latent states.

The right panel shows the maximum log-likelihood for different combinations of SPI and SDI rolling-window sizes (3-, 6-, 9-, and 12-month), visualised as a heatmap. The results indicate that the 12-month window for both indices yields the highest likelihood, highlighted by the red box.

\begin{figure}[!h]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{model-select-plot.png}
        \caption{Model selection criteria (AIC, BIC, and maximum log-likelihood) plotted against the number of hidden states $m$. The optimal value of $m$ is indicated by a vertical red dotted line.}
        \label{fig:model-select-plot}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{model-select-rolling-windows.png}
        \caption{Maximum log-likelihood values for different SPI and SDI window combinations. The 12-month window for both indices (red box) yields the optimal model performance.}
        \label{fig:model-select-rolling-windows}
    \end{subfigure}
    \caption[Model Selection Results]{Model selection results comparing different hyperparameters.}
    \label{fig:model-selection-combined}
\end{figure}

With the optimal number of latent drought states determined as $m=6$, subsequent analyses use the following classification of latent states:
\begin{align*}
    1 &: (S3D) = \text{Extreme Drought}, \\
    2 &: (S2D) = \text{Moderate Drought}, \\
    3 &: (S1D) = \text{Mild Drought}, \\
    4 &: (S1W) = \text{Mild Wet}, \\
    5 &: (S2W) = \text{Moderate Wet}, \\
    6 &: (S3W) = \text{Extreme Wet.}
\end{align*}
To be explicit, for the performance analysis that follows, latent states 1--3 ($S_t \leq 3$) were classified as ``drought'', while states 4--6 ($S_t > 3$) were classified as ``non-drought'', as mentioned in Section~\ref{sec:overview_design}.

\section{Model Behaviour}

This section qualitatively examines the performance and interpretability of the DNBC by looking at how it behaves when exposed to the data. Specifically, the Viterbi-decoded state sequence and the relationship between the model’s output and the original input indices is explored.

\subsection{Latent-State Sequence Output}

Figure~\ref{fig:model-output-time-series} presents the Viterbi-decoded state sequence for the entire study period 1981 to 2019, along with the known historical drought periods identified in literature as shaded regions, that being 1983--1984, 1991--1992, 1994--1995, 2000--2001, 2003--2004, 2014--2016, and 2017--2018.
\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{model-output-time-series.png}
    \caption[DNBC State Sequence]{Viterbi-decoded state sequence of the DNBC with known drought periods as shaded regions.}
    \label{fig:model-output-time-series}
\end{figure}

The model demonstrates a mixed but promising capacity for identifying historical drought periods. It successfully captures the two major droughts in the 2000--2004 period, with latent states distinctly shifting lower. Performance for other events is more varied as the model identifies the 1983--1984 and 2014--2018 droughts, albeit with a noticeable delay, and fails to react to the 1991--1992 event completely.

Despite these inconsistencies, the model exhibits a clear tendency to enter lower drought states during known drought events. This indicates that the DNBC has learned to characterise drought conditions to some extent, successfully integrating the three input indices.

\subsection{Model Confidence and Input Comparison}

To better visualise the relationships between the input indices and the model output, Figure~\ref{fig:model-input-output} shows the SPI, SDI, and NDVI time series alongside the DNBC output. At each monthly time step, the DNBC's output has a confidence attached which is represented by the height of the vertical bar. This confidence is derived from the MPM rule probabilities while the colour represents the classification which comes from the Viterbi output.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{indcies-time-series.png}
    \caption[Indices and Model Output Time Series]{Drought classifications for the period 1981--2019 using SPI, SDI, NDVI, and DNBC (the vertical, coloured bars represent different drought states, while their height indicates the confidence in classification. The black lines plot the continuous values of SPI, SDI and NDVI)}
    \label{fig:model-input-output}
\end{figure}

This graph shows that the input indices themselves are inherently noisy and oscillatory, reflecting the high variability of environmental conditions and could in turn contribute to the model's uncertain classifications that are present in the plot, particularly at state transitions. Nonetheless, this probabilistic approach allows these uncertainties to be explicitly shown, which the standard indices lack.

\section{Quantitative Evaluation}

A quantitative evaluation was conducted by treating known drought events as a binary classification problem. For the period 1981--2019, each month was classified as either a drought, considered the positive class, or non-drought, the negative class. The predictions from the model and each input index were then compared against the historical classifications. The resulting confusion matrices are presented in Figure~\ref{fig:confusion-matrices}. Using these matrices, performance metrics were calculated and are summarised in Table~\ref{tbl:performance_metrics}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{confusion-matrices.png}
    \caption[Confusion Matrices for Drought Classifications]{Confusion matrices for classifying known drought states using (a) SPI, (b) SDI, (c) NDVI, (d) DNBC.}
    \label{fig:confusion-matrices}
\end{figure}

\begin{table}[!h]
    \centering
    \caption[Performance Metrics of Input Indices and DNBC]{Performance comparison of three input indices (SPI, SDI, NDVI) and the DNBC model in classifying drought events. The models are evaluated using four standard metrics: recall, accuracy, precision, and F1 score.}
    \label{tbl:performance_metrics}
    \begin{tabular}{lccccc}
        \toprule
        Indicator & Recall (\%) & Accuracy (\%) & Precision (\%)  & F1 Score (\%) \\
        \midrule
        SPI       & 51.67   & 53.78         & 42.27           & 46.50         \\
        SDI       & 62.22   & 59.61         & 48.48           & 54.50         \\
        NDVI      & 73.33   & 40.82         & 36.87           & 49.07         \\
        DNBC      & 46.67   & 73.43         & 75.68           & 57.73         \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Performance Metrics and Interpretation}

Recall and precision evaluate two distinct and critical aspects of model performance in the context of drought monitoring. Recall measures the model's ability to correctly identify actual drought events. Thus, high recall is crucial for a warning system, as it means fewer droughts are missed. Conversely, precision measures the reliability of the model's drought alarms as it indicates that when the model predicts a drought, it is likely to be correct. In practice, scoring high in precision directly reduces false alarms and associated costs for decision-makers.

The F1-score, defined as the harmonic mean of precision and recall, provides a single metric that balances these two concerns. It is particularly informative in highly imbalanced datasets such as this one where drought events form a small fraction of the total. Finally, accuracy can be misleading in this context, since a model that always predicts ``no drought'' could achieve high accuracy simply due to class imbalance. Hence, F1-score is the most appropriate performance metric for this application.

The following observations can be made from the results:

\begin{itemize}
    \item \textbf{NDVI:} Exhibits high recall ($73.3\%$) but low precision ($36.9\%$), indicating that it frequently identifies drought conditions, including many false alarms. This could be due to NDVI’s sensitivity to the agricultural aspect of drought, which can both lag or persist beyond meteorological drought. This will lead to overestimation.
    \item \textbf{SPI:} Shows moderate recall ($51.7\%$) paired with lower precision ($42.3\%$), suggesting the same behaviour as the NDVI, just to a lesser extent.
    \item \textbf{SDI:} Achieves higher values than the SPI for both recall ($62.2\%$) and precision ($48.5\%$). SDI therefore offers a slight improvement to the SPI, as shown by the increased F1-score ($54.5\%$)
    \item \textbf{DNBC Output (Viterbi):} Marginally achieves the highest F1-score ($57.7\%$), with the lowest recall ($46.67\%$) but the largest precision ($75.7\%$). This suggests the model misses true drought events, but its drought classifications are reliable, resulting in a conservative classifier.
\end{itemize}






